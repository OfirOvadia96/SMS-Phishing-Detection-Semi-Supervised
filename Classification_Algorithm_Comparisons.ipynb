{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons between different classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "f_path = './dataset/SMSSpamCollection.csv'\n",
    "dataset = pd.read_csv(f_path,sep='\\t',names=[\"label\",\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A graph illustrating the ratio between ham and spam\n",
    "plt.rcParams[\"figure.figsize\"] = [8,10] \n",
    "dataset.label.value_counts().plot(kind='pie', autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list that contains a number of words in ham messages and their count of occurrence in the dataset\n",
    "dataset_ham = dataset[dataset['label'] == \"ham\"]\n",
    "dataset_ham_count = dataset_ham['message'].str.split().str.len()\n",
    "dataset_ham_count.index = dataset_ham_count.index.astype(str) + ' words:'\n",
    "dataset_ham_count.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list that contains a number of words in spam messages and their count of occurrence in the dataset\n",
    "dataset_spam = dataset[dataset['label'] == \"spam\"]\n",
    "dataset_spam_count = dataset_spam['message'].str.split().str.len()\n",
    "dataset_spam_count.index = dataset_spam_count.index.astype(str) + ' words:'\n",
    "dataset_spam_count.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 50, 10)\n",
    "\n",
    "plt.hist([dataset_ham_count, dataset_spam_count], bins, label=['ham', 'spam'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# The output shows that most of the ham messages contain 0 to 10 words \n",
    "# while the majority of spam messages are longer and contain between 20 to 30 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[\"message\"]  \n",
    " \n",
    "y = dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing numbers and special characters\n",
    "\n",
    "def text_preprocess(sen): \n",
    "\n",
    "   sen = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "   sen = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sen)\n",
    "   sen = re.sub(r'\\s+', ' ', sen)\n",
    "\n",
    "   return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to list after preprocessing\n",
    "X_messages = [] \n",
    "messages = list(X) \n",
    "for mes in messages: \n",
    "    X_messages.append(text_preprocess(mes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Text to Numbers\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "tfidf_vec = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english')) \n",
    "X = tfidf_vec.fit_transform(X_messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of 7 supervised algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB(alpha = 0.5)\n",
    "mnb.fit(X_train,y_train)\n",
    "\n",
    "y_mnb = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy:  0.9834888729361091\n",
      "Naive Bayes confusion_matrix:  [[1203   19]\n",
      " [   4  167]]\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes Accuracy: ', accuracy_score( y_mnb , y_test))\n",
    "print('Naive Bayes confusion_matrix: ', confusion_matrix(y_mnb, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=250, random_state=0) \n",
    "rf_clf.fit(X_train, y_train) \n",
    "\n",
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RandomForest confusion_matrix: ',confusion_matrix(y_test,y_pred)) \n",
    "print('RandomForest Accuracy: ',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "svc.fit(X_train,y_train)\n",
    "y_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM Accuracy: ', accuracy_score(y_svc , y_test))\n",
    "print('SVM confusion_matrix: ', confusion_matrix(y_svc, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors=100)\n",
    "knc.fit(X_train,y_train)\n",
    "\n",
    "y_knc = knc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNeighbors Accuracy_score: ',accuracy_score(y_test,y_knc))\n",
    "print('KNeighbors confusion_matrix: ', confusion_matrix(y_test, y_knc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(min_samples_split=7, random_state=252)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_dtc = dtc.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decision Tree Accuracy: ',accuracy_score(y_test,y_dtc))\n",
    "print('Decision Tree confusion_matrix: ', confusion_matrix(y_dtc, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators=37, random_state=252)\n",
    "etc.fit(X_train,y_train)\n",
    "y_etc = etc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extra Tree Accuracy_score: ',accuracy_score(y_test,y_etc))\n",
    "print('Extra Tree confusion_matrix: ', confusion_matrix(y_etc, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bc = BaggingClassifier(n_estimators=9, random_state=252)\n",
    "bc.fit(X_train,y_train)\n",
    "y_bc = bc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bagging Accuracy_score: ',accuracy_score(y_test,y_bc))\n",
    "print('Bagging confusion_matrix: ', confusion_matrix(y_bc, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=37, random_state=252)\n",
    "abc.fit(X_train,y_train)\n",
    "y_abc = abc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AdaBoost Accuracy_score: ',accuracy_score(y_test,y_abc))\n",
    "print('AdaBoost confusion_matrix: ', confusion_matrix(y_abc, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for new sentence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['love this place have been coming here since was kid The food is always good and the service is great It great place to go for quick bite to eat or late night snack You can go wrong with any of the items on the menu They have wide variety of appetizers entrees and desserts']\n",
    "sen = tfidf_vec.transform(sentence).toarray() # Fit the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_Naive_Bayes = mnb.predict(sen) # Naive Bayes\n",
    "print(\"Naive_Bayes: \", prediction_Naive_Bayes)\n",
    "prediction_RandomForest = rf_clf.predict(sen) # Random Forest\n",
    "print(\"RandomForest: \", prediction_RandomForest)\n",
    "prediction_SVM = svc.predict(sen) # SVM\n",
    "print(\"SVM: \", prediction_SVM)\n",
    "prediction_KNeighbors = knc.predict(sen) # KNeighbors\n",
    "print(\"KNeighbors: \", prediction_KNeighbors)\n",
    "prediction_Decision_Tree = dtc.predict(sen) # Decision_Tree\n",
    "print(\"Decision Tree: \", prediction_Decision_Tree)\n",
    "prediction_Bagging = bc.predict(sen) # Bagging\n",
    "print(\"Bagging: \", prediction_Bagging)\n",
    "prediction_AdaBoost = abc.predict(sen) # AdaBoost\n",
    "print(\"AdaBoost: \", prediction_AdaBoost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('NaiveBayes_model','wb') as f:\n",
    "    pickle.dump(mnb,f)\n",
    "\n",
    "with open('RandomForest_model','wb') as f:\n",
    "    pickle.dump(rf_clf,f)\n",
    "\n",
    "with open('SVM_model','wb') as f:\n",
    "    pickle.dump(svc,f)\n",
    "    \n",
    "with open('KNeighbors_model','wb') as f:\n",
    "    pickle.dump(knc,f)\n",
    "\n",
    "with open('DecisionTree_model','wb') as f:\n",
    "    pickle.dump(dtc,f)\n",
    "\n",
    "with open('Bagging_model','wb') as f:\n",
    "    pickle.dump(bc,f)\n",
    "\n",
    "with open('AdaBoost_model','wb') as f:\n",
    "    pickle.dump(abc,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with the larged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f_path1 = './dataset/SMSSpamCollection.csv'\n",
    "dataset = pd.read_csv(f_path1, sep='\\t',names=[\"label\",\"message\"])\n",
    "\n",
    "f_path2 = './dataset/SyntheticMessages_WithLabel.csv'\n",
    "synthetic_dataset = pd.read_csv(f_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  5572\n",
      "synthetic dataset size:  923\n",
      "large dataset size:  6495\n"
     ]
    }
   ],
   "source": [
    "frames = [dataset, synthetic_dataset]\n",
    "\n",
    "large_dataset = pd.concat(frames)\n",
    "\n",
    "print(\"dataset size: \",len(dataset))\n",
    "print(\"synthetic dataset size: \",len(synthetic_dataset))\n",
    "print(\"large dataset size: \",len(large_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = large_dataset[\"message\"]  \n",
    "y = large_dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = large_dataset[\"message\"].apply(str)\n",
    "\n",
    "X_messages = [] \n",
    "messages = list(X) \n",
    "for mes in messages: \n",
    "    X_messages.append(text_preprocess(mes))\n",
    "\n",
    "# Converting Text to Numbers\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "tfidf_vec = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english')) \n",
    "X = tfidf_vec.fit_transform(X_messages).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing Data into Training and Test Sets - Large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB(alpha = 0.5)\n",
    "mnb.fit(X_train,y_train)\n",
    "\n",
    "y_mnb = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy:  0.9852216748768473\n",
      "Naive Bayes confusion_matrix:  [[1434   22]\n",
      " [   2  166]]\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "\n",
    "print('Naive Bayes Accuracy: ', accuracy_score( y_mnb , y_test))\n",
    "print('Naive Bayes confusion_matrix: ', confusion_matrix(y_mnb, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=250, random_state=0) \n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "print('RandomForest confusion_matrix: ',confusion_matrix(y_test,y_pred)) \n",
    "print('RandomForest Accuracy: ',accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
